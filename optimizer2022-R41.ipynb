{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f7bd005",
   "metadata": {},
   "source": [
    "# Optimizer 2022 R41 Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b250f7",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2968131",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sympy import symbols, solve\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import networkx.algorithms.community as nx_comm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b82dd1",
   "metadata": {},
   "source": [
    "### useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "194d6994",
   "metadata": {
    "code_folding": [
     0,
     6,
     10,
     176,
     199,
     294,
     305,
     314,
     320,
     328,
     334,
     342,
     356,
     369,
     387,
     400,
     407,
     419,
     429,
     433,
     447,
     473,
     558,
     580
    ]
   },
   "outputs": [],
   "source": [
    "def factorial(n):\n",
    "    if n == 1:\n",
    "        return 1\n",
    "    return factorial(n-1)*n\n",
    "\n",
    "\n",
    "def combinations(n, k):\n",
    "    return factorial(n)/(factorial(n-k)*factorial(k))\n",
    "\n",
    "\n",
    "class Point:\n",
    "    def __init__(self, label, coords, deg=0, adj_list=None):\n",
    "        if adj_list is None:\n",
    "            adj_list = set()\n",
    "        self.label = label\n",
    "        self.coords = coords\n",
    "        self.deg = deg\n",
    "        self.adj_list = adj_list\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"point: %s\\ndeg: %s\" % (str(self.label), str(self.deg))\n",
    "\n",
    "\n",
    "class Network:\n",
    "    def __init__(self, nnodes=0, node_dict=None, links=None):\n",
    "        if node_dict is None:\n",
    "            node_dict = dict()\n",
    "        if links is None:\n",
    "            links = set()\n",
    "        self.nnodes = nnodes\n",
    "        self.node_dict = node_dict\n",
    "        self.links = links\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def louvain(self, edges, resolution):\n",
    "        G = nx.Graph()\n",
    "        for i in range(1, self.nnodes+1):\n",
    "            G.add_node(i)\n",
    "        G.add_weighted_edges_from(edges)\n",
    "        components = nx_comm.louvain_communities(G, resolution=resolution)\n",
    "        return components\n",
    "    \n",
    "    \n",
    "    \n",
    "    def modularity(self):\n",
    "        self.net_out('dfs_in.txt')\n",
    "        cpp_run('./dfs')\n",
    "        lb = dfs_read('./dfs_out.txt')\n",
    "        nc = len(np.unique(np.asarray(lb)))\n",
    "        components = [[] for i in range(nc)]\n",
    "        for i in range(1, self.nnodes+1):\n",
    "            components[lb[i-1]-1].append(i)\n",
    "        M = 0\n",
    "        for i in range(nc):\n",
    "            kc = 0\n",
    "            for j in components[i]:\n",
    "                kc += self.node_dict[j].deg\n",
    "            lc = kc/2\n",
    "            L = len(self.links)\n",
    "            mc = (lc/L)-(kc/2*L)**2\n",
    "            M += mc\n",
    "        return M\n",
    "        \n",
    "    \n",
    "    def add_node(self, node):\n",
    "        self.nnodes = self.nnodes + 1\n",
    "        self.node_dict[node.label] = node\n",
    "\n",
    "\n",
    "    def add_undir_link(self, node1, node2):\n",
    "        self.node_dict[node1].adj_list.add(node2)\n",
    "        self.node_dict[node1].deg += 1       \n",
    "        self.node_dict[node2].adj_list.add(node1)\n",
    "        self.node_dict[node2].deg += 1\n",
    "        self.links.add((node1, node2))\n",
    "              \n",
    "    \n",
    "    def find_distance(self):\n",
    "        mx = 0\n",
    "        mn = math.inf\n",
    "        distances = []\n",
    "        for i in range(1, self.nnodes+1):\n",
    "            for j in range(i, self.nnodes+1):\n",
    "                d = math.dist(self.node_dict[i].coords, self.node_dict[j].coords)\n",
    "                distances.append(d)\n",
    "                if d > mx:\n",
    "                    mx = d\n",
    "                if d < mn:\n",
    "                    mn = d\n",
    "        return mx, mn, np.mean(np.asarray(distances)), np.std(np.asarray(distances))\n",
    "     \n",
    "    \n",
    "    def create_epsilon_neighbour_graph(self, epsilon):\n",
    "        for i in range(1, self.nnodes+1):\n",
    "            for j in range(i+1, self.nnodes+1):\n",
    "                d = math.dist(self.node_dict[i].coords, self.node_dict[j].coords)\n",
    "                if d < epsilon:\n",
    "                    self.add_undir_link(i, j)\n",
    "    \n",
    "    \n",
    "    def create_k_neighbour_graph(self, k):\n",
    "        for i in range(1, self.nnodes+1):\n",
    "            nodes = []\n",
    "            for j in range(1, self.nnodes+1):\n",
    "                d = dist(np.asarray(self.node_dict[i].coords), np.asarray(self.node_dict[j].coords))\n",
    "                nodes.append((j, d))\n",
    "            nodes.sort(key=lambda x:x[1])\n",
    "            for j in range(1, k+1):\n",
    "                self.add_undir_link(i, nodes[k][0])\n",
    "    \n",
    "    \n",
    "    def create_complete_graph(self):\n",
    "        for i in range(1, self.nnodes+1):\n",
    "            for j in range(i+1, self.nnodes+1):\n",
    "                self.add_undir_link(i, j)\n",
    "                \n",
    "    \n",
    "    def find_minmax(self):\n",
    "        mx = 0\n",
    "        mn = math.inf\n",
    "        for link in self.links:\n",
    "            node1 = link[0]\n",
    "            node2 = link[1]\n",
    "            d = math.dist(self.node_dict[node1].coords, self.node_dict[node2].coords)\n",
    "            if d > mx:\n",
    "                mx = d\n",
    "            if d < mn:\n",
    "                mn = d\n",
    "        return mx, mn\n",
    "                  \n",
    "    \n",
    "    def add_edge_weights(self):\n",
    "        edges = []\n",
    "        mx, mn = self.find_minmax()\n",
    "        for link in self.links:\n",
    "            node1 = link[0]\n",
    "            node2 = link[1]\n",
    "            d = math.dist(self.node_dict[node1].coords, self.node_dict[node2].coords)\n",
    "            edges.append((node1, node2, (d-mn)/(mx-mn)))\n",
    "        edges.sort(key=lambda x:x[2])\n",
    "        return edges\n",
    "     \n",
    "    \n",
    "    def add_edge_distance(self):\n",
    "        edges = []\n",
    "        for link in self.links:\n",
    "            node1 = link[0]\n",
    "            node2 = link[1]\n",
    "            d = math.dist(self.node_dict[node1].coords, self.node_dict[node2].coords)\n",
    "            edges.append((node1, node2, d))\n",
    "        edges.sort(key=lambda x:x[2])\n",
    "        return edges\n",
    "    \n",
    "    \n",
    "    def edge_list_out(self, file_path):\n",
    "        edges = self.add_edge_distance()\n",
    "        with open(file_path, 'w') as f:\n",
    "            f.write(\"%s\\n\" % str(len(edges)))\n",
    "            for edge in edges:\n",
    "                node1 = edge[0]\n",
    "                node2 = edge[1]\n",
    "                weight = edge[2]\n",
    "                f.write(\"%s %s %s\\n\" %(str(node1), str(node2), str(weight)))\n",
    "    \n",
    "    \n",
    "    def net_out(self, file_path):\n",
    "        with open(file_path, 'w') as f:\n",
    "            f.write(\"%s\\n\" % str(self.nnodes))\n",
    "            for k in self.node_dict.keys():\n",
    "                f.write(\"%s \" % str(self.node_dict[k].deg))\n",
    "                f.write(\" \".join(str(e) for e in self.node_dict[k].adj_list))\n",
    "                f.write(\"\\n\")\n",
    "    \n",
    "       \n",
    "def read_input(input_dir):\n",
    "    point_list = []\n",
    "    with open(input_dir, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        d, n, m, k, rho = lines[0].strip().split()\n",
    "        k_i = lines[1].strip().split()\n",
    "        for line in lines[2:]:\n",
    "            new = np.float32(line.strip().split())\n",
    "            point_list.append(list(new))\n",
    "    return [int(d), int(n) , m, k, int(rho), [int(e) for e in k_i]], create_df(point_list)\n",
    "\n",
    "\n",
    "def show_input_params(input_params):\n",
    "    print(\"d: %i\" % input_params[0])\n",
    "    print(\"n: %i\" % input_params[1])\n",
    "    print(\"m: %s\" % input_params[2])\n",
    "    print(\"k: %s\" % input_params[3])\n",
    "    print(\"k_i: \", end=\"\")\n",
    "    print(\" \".join(str(e) for e in input_params[5]))\n",
    "    print(\"rho: %i\" % input_params[4])\n",
    "    return\n",
    "    \n",
    "\n",
    "def gng(points, max_iter, epsilon_b, epsilon_n, a_max, lambda_, alpha, D):\n",
    "    w = []\n",
    "    w_ab = random.sample(points, 2)\n",
    "    for i in w_ab:\n",
    "        w.append(i)\n",
    "    it = 0\n",
    "    while it < max_iter:\n",
    "        x = random.sample(points, 1)\n",
    "        x = x[0]\n",
    "        min_dist = math.inf\n",
    "        min_dist2 = math.inf\n",
    "        w_s1_idx = -1\n",
    "        w_s2_idx = -1\n",
    "        w_s1 = 'a'\n",
    "        w_s2 = 'a'\n",
    "        for i in range(len(w)):\n",
    "            d = math.dist(w[i].coords, x.coords)\n",
    "            if d < min_dist:\n",
    "                min_dist2 = min_dist\n",
    "                w_s2_idx = w_s1_idx\n",
    "                w_s2 = w_s1\n",
    "                min_dist = d\n",
    "                w_s1_idx = i\n",
    "                w_s1 = w[i]\n",
    "            elif d < min_dist2:\n",
    "                min_dist2 = d\n",
    "                w_s2_idx = i\n",
    "                w_s2 = w[i]\n",
    "        w[w_s1_idx].error += math.dist(w_s1.coords, x.coords)**2\n",
    "        w[w_s1_idx].coords = tuple(np.asarray(w_s1.coords) + epsilon_b*(np.asarray(x.coords)-np.asarray(w_s1.coords)))\n",
    "        for i in w[w_s1_idx].adj_list:\n",
    "            w[i[0]].coords = tuple(np.asarray(w[i[0]].coords)+epsilon_n*(np.asarray(x.coords)-np.asarray(w[i[0]].coords)))\n",
    "        if w_s2_idx not in w[w_s1_idx].adj_list:\n",
    "            w[w_s1_idx].adj_list.append([w_s2_idx, 0])\n",
    "            w[w_s2_idx].adj_list.append([w_s1_idx, 0])\n",
    "            w[w_s1_idx].deg += 1\n",
    "            w[w_s2_idx].deg += 1\n",
    "        for p in w:\n",
    "            i = 0\n",
    "            while i < len(p.adj_list):\n",
    "                if p.adj_list[i][1] > a_max:\n",
    "                    del p.adj_list[i]\n",
    "                i += 1\n",
    "        i = 0\n",
    "        while i < len(w):\n",
    "            if w[i].deg == 0:\n",
    "                del w[i]\n",
    "            i += 1\n",
    "        if it % lambda_ == 0:\n",
    "            w_q_idx = -1\n",
    "            max_err = 0\n",
    "            for i in range(len(w)):\n",
    "                if w[i].error < max_err:\n",
    "                    max_err = w[i].error\n",
    "                    w_q_idx = i\n",
    "            w_r_idx = -1\n",
    "            max_err = 0\n",
    "            for p in w[w_q_idx].adj_list:\n",
    "                if w[p[0]].error > max_err:\n",
    "                    max_err = w[p[0]].error\n",
    "                    w_r_idx = p[0]\n",
    "            w_s_coords = tuple((np.asarray(w[w_q_idx].coords)+np.asarray(w[w_r_idx].coords))/2)\n",
    "            w.append(Point(label=len(w)+1, coords=w_s_coords))\n",
    "            w[-1].adj_list.append([w_q_idx, 0])\n",
    "            w[-1].adj_list.append([w_r_idx, 0])\n",
    "            w[1].deg += 2\n",
    "            w[w_r_idx].adj_list.append([len(w)-1, 0])\n",
    "            w[w_q_idx].adj_list.append([len(w)-1, 0])\n",
    "            w[w_r_idx].deg += 1\n",
    "            w[w_q_idx].deg += 1\n",
    "            i = 0\n",
    "            while i < len(w[w_q_idx].adj_list):\n",
    "                if w[w_q_idx].adj_list[i][0] == w_r_idx:\n",
    "                    del w[w_q_idx].adj_list[i]\n",
    "                    break\n",
    "                i += 1\n",
    "            i = 0\n",
    "            while i < len(w[w_r_idx].adj_list):\n",
    "                if w[w_r_idx].adj_list[i][0] == w_q_idx:\n",
    "                    del w[w_q_idx].adj_list[i]\n",
    "                    break\n",
    "                i += 1\n",
    "            w[w_q_idx].error *= alpha\n",
    "            w[w_r_idx].error *= alpha\n",
    "            w[-1].error = w[w_q_idx].error\n",
    "\n",
    "            for p in w:\n",
    "                p.error *= D\n",
    "\n",
    "#             if termination:\n",
    "#                 break\n",
    "        it += 1\n",
    "    return w\n",
    "\n",
    "\n",
    "def vector_quantization(method, points, n_output, miter=None):\n",
    "    if method.lower() == 'kmeans' or method.lower() == 'k-means':\n",
    "        if miter == None:   \n",
    "            k = KMeans(n_clusters=n_output)\n",
    "            k.fit(points)\n",
    "            centers = k.cluster_centers_\n",
    "            labels = k.labels_\n",
    "            return centers, labels\n",
    "    \n",
    "    \n",
    "    \n",
    "def vector_quantization_mini(method, points, n_output, miter):\n",
    "    if method.lower() == 'minibatchkmeans' or method.lower() == 'mini-batch-kmeans':\n",
    "        k = MiniBatchKMeans(n_clusters=n_output, batch_size=3072, max_iter=miter)\n",
    "        k.fit(points)\n",
    "        centers = k.cluster_centers_\n",
    "        labels = k.labels_\n",
    "        return centers, labels\n",
    "\n",
    "\n",
    "def dimensionality_reduction(points, old_dim, new_dim):\n",
    "    pca = PCA(n_components=new_dim)\n",
    "    new_points = pca.fit_transform(X=points)\n",
    "    return create_df(new_points)\n",
    "\n",
    "\n",
    "def kmeans_clustering(points, k):\n",
    "    k = KMeans(n_clusters=k)\n",
    "    k.fit(points)\n",
    "    centers = k.cluster_centers_\n",
    "    labels = k.labels_\n",
    "    return centers, labels\n",
    "\n",
    "\n",
    "def attach_label_to_point(points, labels):\n",
    "    df = create_df(points)\n",
    "    df['label'] = labels\n",
    "    return df.values\n",
    "\n",
    "\n",
    "def quantized_to_origianl(org_df, qdf):\n",
    "    final_labels = []\n",
    "    for i in range(len(labels)):\n",
    "        final_labels.append(clustered_quantized_points[labels[i], clustered_quantized_points.shape[1]-1])\n",
    "    clustered = np.hstack(points, final_labels)\n",
    "    return clustered\n",
    "    \n",
    "    \n",
    "def points_to_centers_map(points, centers):\n",
    "    labels = []\n",
    "    for i in points:\n",
    "        mn = math.inf\n",
    "        l = -1\n",
    "        for j in range(len(centers)):\n",
    "            d = math.dist(i, centers[j])\n",
    "            if d < mn:\n",
    "                mn = d\n",
    "                l = j\n",
    "        labels.append(l)\n",
    "    return labels\n",
    "\n",
    "\n",
    "def lower_dimension(cluster:np.ndarray, dim, error):\n",
    "    points = []\n",
    "    for i in range(dim):\n",
    "        points.append(cluster[i])\n",
    "    A = np.asarray(points)\n",
    "    b = np.ones((dim,))\n",
    "    coefs = np.linalg.inv(A).dot(b)\n",
    "    rnd = random.choice(cluster[dim:])\n",
    "    if abs(coefs.dot(rnd) - 1) < error:\n",
    "        return True, coefs/np.linalg.norm(coefs), rnd.dot(coefs/np.linalg.norm(coefs))\n",
    "    return False, coefs/np.linalg.norm(coefs), rnd.dot(coefs/np.linalg.norm(coefs))\n",
    "\n",
    "\n",
    "def lower_dimension_2(cluster:np.ndarray, dim, error):\n",
    "    x = symbols('x')\n",
    "    p1 = cluster[dim+10]\n",
    "    p2 = cluster[dim+11]\n",
    "    vec1 = p1 - p2\n",
    "    vec2 = np.ones((dim-1,))\n",
    "    vec2 = np.append(vec2, x)\n",
    "    f = vec1.dot(vec2)\n",
    "    s = solve(f)\n",
    "    nor = np.ones((dim-1,))\n",
    "    nor = np.append(nor, np.asarray(s))\n",
    "    D = nor.dot(p1)\n",
    "    rnd = random.choice(cluster[dim:])\n",
    "    if abs(nor.dot(rnd) - D) < error:\n",
    "        return True, nor, D\n",
    "    return False, nor, D\n",
    "    \n",
    "\n",
    "def find_center_radius(cluster):\n",
    "    diameter = 0\n",
    "    for i in range(cluster.shape[0]):\n",
    "        for j in range(i+1, cluster.shape[0]):\n",
    "            p1 = cluster[i]\n",
    "            p2 = cluster[j]\n",
    "            d = math.dist(p1, p2)\n",
    "            if d > diameter:\n",
    "                diameter = d\n",
    "                center = (p1+p2)/2\n",
    "    return center, diameter/2\n",
    "\n",
    "\n",
    "def index_list(df, k):\n",
    "    total = [[] for i in range(k)]\n",
    "    for i in range(len(df)):\n",
    "        total[df['label'].iloc[i]].append(i+1)\n",
    "    return total\n",
    "\n",
    "\n",
    "def write_manifold(output_path, manifold_type, dim, df):\n",
    "    if manifold_type.lower() == 'complex':\n",
    "        k_i = len(df['cluster'].unique())\n",
    "        with open(output_path, 'a') as f:\n",
    "            f.write(\"%i %i Complex\\n\" % (dim, k_i))\n",
    "            for i in range(k_i):\n",
    "                indexes = df[df['cluster']==i].index\n",
    "                f.write(\"%i \" % len(indexes))\n",
    "                f.write(\" \".join(str(e) for e in indexes))\n",
    "                f.write(\"\\n\")\n",
    "        \n",
    "\n",
    "def write_output(output_path, input_params, dim:dict, df):\n",
    "    d, n, m, k, rho, k_i = input_params\n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write(\"%i %i\\n\" % (n, m))\n",
    "    for i in range(m):\n",
    "        man_df = df[df['manifold']==i]\n",
    "        write_manifold(output_path, 'complex', dim[i], man_df)\n",
    "\n",
    "        \n",
    "        \n",
    "def create_df(point_list):\n",
    "    return pd.DataFrame(point_list, index=pd.RangeIndex(1, len(point_list)+1, 1))\n",
    "\n",
    "\n",
    "def find_initial_components(df, m):\n",
    "    points = df.values\n",
    "    net = Network()\n",
    "    for i in range(1, points.shape[0]+1):\n",
    "        p = Point(i, tuple(points[i-1]))\n",
    "        net.add_node(p)\n",
    "    for i in net.node_dict.keys():\n",
    "        for j in net.node_dict.keys():\n",
    "            d = math.dist(net.node_dict[i].coords, net.node_dict[j].coords)\n",
    "            if d < thr:\n",
    "                net.add_undir_link()\n",
    "                \n",
    "                \n",
    "\n",
    "def cpp_run(file_path):\n",
    "\n",
    "    process = subprocess.Popen(file_path, shell=False)\n",
    "\n",
    "    out, err = process.communicate()\n",
    "    errcode = process.returncode\n",
    "    \n",
    "    process.kill() \n",
    "    process.terminate()\n",
    "                \n",
    "                \n",
    "def mst_read(input_dir, k):\n",
    "    edges = []\n",
    "    with open(input_dir, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        if k != 1:\n",
    "            for line in lines[:-(k-1)]:\n",
    "                node1, node2, weight = line.strip().split()\n",
    "                edges.append((int(node1), int(node2), float(weight)))\n",
    "        else:\n",
    "            for line in lines:\n",
    "                node1, node2, weight = line.strip().split()\n",
    "                edges.append((int(node1), int(node2), float(weight)))\n",
    "    return edges\n",
    "\n",
    "\n",
    "def dfs_read(input_dir):\n",
    "    label = []\n",
    "    with open(input_dir, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines[1:]:\n",
    "            label.append(int(line))\n",
    "    return label\n",
    "            \n",
    "\n",
    "def manifold(df, clusters=None):\n",
    "    print(\"Creating Network ...\")\n",
    "    net = Network()\n",
    "    for i in range(1, len(df)+1):\n",
    "        coords = []\n",
    "        for j in range(len(df.columns)):\n",
    "            coords.append(df.iloc[i-1][j])\n",
    "        p = Point(i, coords=coords)\n",
    "        net.add_node(p)\n",
    "    net.create_complete_graph()\n",
    "    \n",
    "#     print(\"Finding Minimal Spanning Tree ...\")\n",
    "#     net.edge_list_out('kruskal_in.txt')\n",
    "#     cpp_run('./kruskal')\n",
    "#     eds = mst_read('kruskal_out.txt', 1)\n",
    "    net.edge_list_out('complete.txt')\n",
    "    eds = mst_read('complete.txt', 1)\n",
    "\n",
    "    resolution = 1\n",
    "    while True:\n",
    "        print(\"Applying Louvain algorithm with resolution %f ...\" % (resolution))\n",
    "        manifolds = net.louvain(eds, resolution)\n",
    "        print(\"%i manifolds detected.\" % (len(manifolds)))\n",
    "        if clusters == None:\n",
    "            clusters = math.inf\n",
    "        if len(manifolds) > clusters:\n",
    "            resolution -= 0.1\n",
    "        else:\n",
    "            break\n",
    "    print(\"Creating new dataframe with detected manifolds ...\")\n",
    "    mans = []\n",
    "    for i in range(len(df)):\n",
    "        for j, manifold in enumerate(manifolds):\n",
    "            if (i+1) in manifold:\n",
    "                mans.append(j+1)\n",
    "                break\n",
    "        \n",
    "    new_df = df.copy()\n",
    "    new_df['manifold'] = mans\n",
    "    return new_df    \n",
    "    \n",
    "    \n",
    "def cluster(df, m, k):\n",
    "    if k == 1:\n",
    "        df['manifold'] = [m for i in range(len(df))]\n",
    "        df['cluster'] = [1 for i in range(len(df))]\n",
    "        return df\n",
    "    net = Network()\n",
    "    for i in range(1, len(df)+1):\n",
    "        coords = []\n",
    "        for j in range(len(df.columns)):\n",
    "            coords.append(df.iloc[i-1][j])\n",
    "        p = Point(i, coords=coords)\n",
    "        net.add_node(p)\n",
    "\n",
    "    net.create_complete_graph()\n",
    "    net.edge_list_out('kruskal_in.txt')\n",
    "    cpp_run('./kruskal')\n",
    "    eds = mst_read('kruskal_out.txt', k)\n",
    "    net2 = Network()\n",
    "    for i in range(1, len(df)+1):\n",
    "        coords = []\n",
    "        for j in range(len(df.columns)):\n",
    "            coords.append(df.iloc[i-1][j])\n",
    "        p = Point(i, coords=coords)\n",
    "        net2.add_node(p)\n",
    "    for i in eds:\n",
    "        net2.add_undir_link(i[0], i[1])\n",
    "    net2.net_out('dfs_in.txt')\n",
    "    cpp_run('./dfs')\n",
    "    lb = dfs_read('dfs_out.txt')\n",
    "    df['manifold'] = [m for i in range(len(df))]\n",
    "    df['cluster'] = lb\n",
    "    return df\n",
    "            \n",
    "            \n",
    "def manifold_to_cluster(df, k_i):\n",
    "    dim = len(df.columns)-1\n",
    "    m = len(df['manifold'].unique())\n",
    "    manifolds = []\n",
    "    clustered_manifolds = []\n",
    "    for i in range(m):\n",
    "        man = df[df['manifold']==i+1]\n",
    "        manifolds.append(man)\n",
    "    manifolds.sort(key=lambda x:len(x), reverse=True)\n",
    "    k_i.sort(reverse=True)\n",
    "    dic = dict()\n",
    "    for i in range(dim):\n",
    "        dic[i] = []\n",
    "    dic['manifold'] = []\n",
    "    dic['cluster'] = []\n",
    "    last_df = pd.DataFrame(dic)\n",
    "    for i in range(len(manifolds)):\n",
    "        new_df = cluster(manifolds[i].drop('manifold', axis=1), i+1, k_i[i])\n",
    "        last_df = last_df.append(new_df)\n",
    "    return last_df\n",
    "    \n",
    "    \n",
    "def prepare_output(first_df, last_df):\n",
    "    data = []\n",
    "    for i in tqdm(first_df.index):\n",
    "        man = -1\n",
    "        cl = -1\n",
    "        coords = first_df.loc[i].values\n",
    "        mn = math.inf\n",
    "        for k in last_df.index:\n",
    "            w = last_df.loc[k].values[:-2]\n",
    "            d = math.dist(coords, w)\n",
    "            if d < mn:\n",
    "                mn = d\n",
    "                man = last_df['manifold'].loc[k]\n",
    "                cl = last_df['cluster'].loc[k]\n",
    "        data.append((i, man, cl))\n",
    "    return data\n",
    "\n",
    "\n",
    "def outlier(points, thr):\n",
    "    outlier_idxs = set()\n",
    "    for col in tqdm(range(points.shape[1])):\n",
    "        dim = []\n",
    "        for row in range(points.shape[0]):\n",
    "            dim.append(((row+1), points[row,col]))\n",
    "        dim.sort(key=lambda x:x[1])\n",
    "        for i in range(1, len(dim)-1):\n",
    "            if dim[i][1] - dim[i-1][1] > thr and dim[i+1][1] - dim[i][1] > thr:\n",
    "                outlier_idxs.add(dim[i][0])\n",
    "    return outlier_idxs\n",
    "#                 print(\"%i %f %f %f\" % (i+1, first_dim[i-1], first_dim[i], first_dim[i+1]))\n",
    "\n",
    "def find_outliers(points, a, b, key):\n",
    "    res = 'a'\n",
    "    it = 0\n",
    "    indexes = []\n",
    "    results = []\n",
    "    thresholds = []\n",
    "    while res != key:\n",
    "        c = (a + b)/2\n",
    "        thresholds.append(c)\n",
    "        print(\"iteration: %i\\nthreshold: %f\" % (it+1, c))\n",
    "        idxs = outlier(points, c)\n",
    "        indexes.append(idxs)\n",
    "        res = len(idxs)\n",
    "        results.append(res)\n",
    "        if res > key:\n",
    "            a = c\n",
    "        elif res < key:\n",
    "            b = c\n",
    "        it += 1\n",
    "        if it > 20:\n",
    "            for i in range(len(indexes)-1, -1, -1):\n",
    "                if results[i] >= key:\n",
    "                    return thresholds[i], indexes[i], results[i]\n",
    "        print(\"outliers: %i\" % res)\n",
    "        print(\"==================================\")\n",
    "    return c, idxs, res\n",
    "        \n",
    "    \n",
    "\n",
    "def write_manifold(output_path, manifold_type, dim, df):\n",
    "    if manifold_type.lower() == 'complex':\n",
    "        k_i = len(df['cluster'].unique())\n",
    "        with open(output_path, 'a') as f:\n",
    "            f.write(\"%i %i Complex\\n\" % (dim, k_i))\n",
    "            for i in range(k_i):\n",
    "                indexes = df[df['cluster']==i+1].index\n",
    "                f.write(\"%i \" % len(indexes))\n",
    "                f.write(\" \".join(str(e) for e in indexes))\n",
    "                f.write(\"\\n\")\n",
    "        \n",
    "\n",
    "\n",
    "def write_outlier(output_path, df):\n",
    "    out = df[df['manifold'] == -1]\n",
    "    out_idx = out.index\n",
    "    with open(output_path, 'a') as f:\n",
    "        f.write(\"%i \"% len(out))\n",
    "        f.write(\" \".join(str(e) for e in out_idx))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "        \n",
    "def write_output(output_path, input_params, dim:dict, df):\n",
    "    d, n, m, k, rho, k_i = input_params\n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write(\"%i %i\\n\" % (n, m))\n",
    "    for i in range(m):\n",
    "        man_df = df[df['manifold']==i+1]\n",
    "        write_manifold(output_path, 'complex', dim[i+1], man_df)\n",
    "\n",
    "    \n",
    "    \n",
    "def find_center_radius(cluster):\n",
    "    diameter = 0\n",
    "    for i in tqdm(range(cluster.shape[0])):\n",
    "        for j in range(i+1, cluster.shape[0]):\n",
    "            p1 = cluster[i]\n",
    "            p2 = cluster[j]\n",
    "            d = math.dist(p1, p2)\n",
    "            if d > diameter:\n",
    "                diameter = d\n",
    "                center = (p1+p2)/2\n",
    "    return center, diameter/2\n",
    "\n",
    "\n",
    "\n",
    "def calculate_sphere_info(df):\n",
    "    points = df.values\n",
    "    center, radius = find_center_radius(points)\n",
    "    center = np.append(center, radius)\n",
    "    return center\n",
    "\n",
    "\n",
    "\n",
    "def write_manifold(output_path, manifold_type, dim, df, sphere_info=None):\n",
    "    k_i = len(df['cluster'].unique())\n",
    "    if manifold_type.lower() == 'complex':\n",
    "        with open(output_path, 'a') as f:\n",
    "            f.write(\"%i %i Complex\\n\" % (dim, k_i))\n",
    "            for i in range(k_i):\n",
    "                indexes = df[df['cluster']==i+1].index\n",
    "                f.write(\"%i \" % len(indexes))\n",
    "                f.write(\" \".join(str(e) for e in indexes))\n",
    "                f.write(\"\\n\")\n",
    "    elif manifold_type.lower() == 'sphere':\n",
    "        with open(output_path, 'a') as f:\n",
    "            f.write(\"%i %i Sphere\\n\\n\" % (dim, k_i))\n",
    "            f.write(\" \".join(str(e) for e in sphere_info))\n",
    "            f.write(\"\\n\")\n",
    "            for i in range(k_i):\n",
    "                indexes = df[df['cluster']==i+1].index\n",
    "                f.write(\"%i \" % len(indexes))\n",
    "                f.write(\" \".join(str(e) for e in indexes))\n",
    "                f.write(\"\\n\")\n",
    "        \n",
    "\n",
    "def write_output(output_path, input_params, dim:dict, df, man_type):\n",
    "    d, n, m, k, rho, k_i = input_params\n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write(\"%i %i\\n\" % (n, m))\n",
    "    for i in range(m):\n",
    "        man_df = df[df['manifold']==i+1]\n",
    "        if man_type.lower() == 'complex':\n",
    "            write_manifold(output_path, 'sphere', dim[i+1], man_df)\n",
    "        elif man_type.lower() == 'sphere':\n",
    "            sphere_info = calculate_sphere_info(man_df.drop(['manifold', 'cluster'], axis=1))\n",
    "            write_manifold(output_path, 'sphere', dim[i+1], man_df, sphere_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21acfb11",
   "metadata": {},
   "source": [
    "### Reading input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1232dd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d: 25\n",
      "n: 119651\n",
      "m: _\n",
      "k: _\n",
      "k_i: \n",
      "rho: 100\n"
     ]
    }
   ],
   "source": [
    "input_params, df = read_input(\"./R41.txt\")\n",
    "show_input_params(input_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a41a71",
   "metadata": {},
   "source": [
    "### Outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f5cb409",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:07<00:00,  3.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = df.values\n",
    "outlier_indexes = outlier(points, 3)\n",
    "len(outlier_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fe37215",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = df.drop(outlier_indexes, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c45f5d",
   "metadata": {},
   "source": [
    "### Vector quantisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e55be8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 21.2 s\n",
      "Wall time: 7.94 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_out = 1000\n",
    "max_iter = 50\n",
    "# points, labels = vector_quantization('kmeans', clean_df.values, n_out)\n",
    "points, labels = vector_quantization_mini('mini-batch-kmeans', clean_df.values, n_out, max_iter)\n",
    "qdf = create_df(points)\n",
    "# quantized_points = gng(points=points, max_iter=10000, epsilon_b=0.5, epsilon_n=0.1, a_max=10, lambda_=10, alpha=0.01, D=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d712b7",
   "metadata": {},
   "source": [
    "### Clustering manifolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6f6a670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Network ...\n",
      "Finding Minimal Spanning Tree ...\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating Network ...\")\n",
    "net = Network()\n",
    "for i in range(1, len(qdf)+1):\n",
    "    coords = []\n",
    "    for j in range(len(qdf.columns)):\n",
    "        coords.append(qdf.iloc[i-1][j])\n",
    "    p = Point(i, coords=coords)\n",
    "    net.add_node(p)\n",
    "net.create_complete_graph()\n",
    "\n",
    "print(\"Finding Minimal Spanning Tree ...\")\n",
    "net.edge_list_out('kruskal_in.txt')\n",
    "cpp_run('./kruskal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da8da20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eds = mst_read('kruskal_out.txt', 28)\n",
    "\n",
    "net = Network()\n",
    "for i in range(1, len(qdf)+1):\n",
    "    coords = []\n",
    "    for j in range(len(qdf.columns)):\n",
    "        coords.append(qdf.iloc[i-1][j])\n",
    "    p = Point(i, coords=coords)\n",
    "    net.add_node(p)\n",
    "for i in eds:\n",
    "    net.add_undir_link(i[0], i[1])\n",
    "net.net_out('dfs_in.txt')\n",
    "cpp_run('./dfs')\n",
    "lb = dfs_read('dfs_out.txt')\n",
    "qdf['manifold'] = lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8adf5d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "manifold_df = qdf.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5edacb",
   "metadata": {},
   "source": [
    "### Clustering inside manifolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d7baff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "manifold_df['cluster'] = [1 for i in range(len(manifold_df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15ffad69",
   "metadata": {},
   "outputs": [],
   "source": [
    "last = manifold_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde8f8b9",
   "metadata": {},
   "source": [
    "### Finding original labels of points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a0e9f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 119551/119551 [00:23<00:00, 5043.36it/s]\n"
     ]
    }
   ],
   "source": [
    "mans = []\n",
    "clus = []\n",
    "for i in tqdm(range(len(clean_df))):\n",
    "    mans.append(last.loc[labels[i]+1]['manifold'])\n",
    "    clus.append(last.loc[labels[i]+1]['cluster'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d624b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['manifold'] = mans\n",
    "clean_df['cluster'] = clus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b76effd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_params[2] = 28\n",
    "input_params[3] = 28\n",
    "input_params[5] = [1 for i in range(28)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee19da2",
   "metadata": {},
   "source": [
    "### Exporting output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32b2c177",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = dict()\n",
    "for i in range(input_params[2]):\n",
    "    dim[i+1] = 1\n",
    "write_output('./output_R41.txt', input_params, dim, clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "057d735f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./output_R41.txt', 'a') as f:\n",
    "    f.write(\"%i \" % 100)\n",
    "    f.write(\" \".join(str(e) for e in outlier_indexes))\n",
    "    f.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
